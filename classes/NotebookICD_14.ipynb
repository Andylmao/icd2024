{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f59a47e-1020-4b32-bfa6-908676dd6c70",
   "metadata": {},
   "source": [
    "# Notebook ICD - 14\n",
    "\n",
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0587e93a-5b3b-4f73-8af0-73616f75734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3378ca-1769-4347-81c8-df94a781fa47",
   "metadata": {},
   "source": [
    "# Naive Bayes desde cero\n",
    "\n",
    "Esta sección implementa la clase NaiveBayesClassifier, que incluye dos métodos principales: fit y predict.\n",
    "\n",
    "El método init inicializa las estructuras de datos que almacenarán las probabilidades a priori de cada clase (self.class_priors), así como las probabilidades condicionales de cada atributo dado una clase (self.likelihoods).\n",
    "\n",
    "El método fit se encarga de calcular las probabilidades a priori de las clases a partir de las frecuencias observadas en los datos de entrenamiento y luego calcula las probabilidades condicionales (likelihoods) aplicando suavizado de Laplace para evitar valores de probabilidad cero cuando no se ha observado un valor de atributo.\n",
    "\n",
    "Finalmente, el método predict toma las instancias de prueba, calcula las probabilidades posteriores para cada clase y asigna la clase con la mayor probabilidad a cada instancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075e267b-be47-4452-841f-229077ce60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}  # Prior probabilities of the classes\n",
    "        self.likelihoods = {}   # Conditional probabilities (likelihoods)\n",
    "        self.classes = None     # Unique classes in the dataset\n",
    "        self.features = None    # Features (attributes)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Get the unique classes and features (attributes)\n",
    "        self.classes = np.unique(y)\n",
    "        self.features = X.columns\n",
    "        total_samples = len(y)  # Total number of training instances\n",
    "        \n",
    "        # Estimate prior probabilities (relative frequency of each class)\n",
    "        class_counts = y.value_counts().to_dict()\n",
    "        self.class_priors = {cls: (class_counts[cls] / total_samples) for cls in self.classes}\n",
    "        \n",
    "        # Initialize conditional probabilities (likelihoods)\n",
    "        self.likelihoods = {cls: {} for cls in self.classes}\n",
    "        \n",
    "        # Calculate the likelihoods (conditional probabilities) for each feature\n",
    "        for cls in self.classes:\n",
    "            X_cls = X[y == cls]  # Filter instances where the class is 'cls'\n",
    "            total_cls_samples = len(X_cls)  # Number of instances per class\n",
    "            \n",
    "            # Calculate the likelihoods for each attribute and attribute value\n",
    "            for feature in self.features:\n",
    "                feature_counts = X_cls[feature].value_counts().to_dict()  # Frequency of each attribute value\n",
    "                total_feature_values = len(X[feature].unique())  # Total number of possible attribute values\n",
    "                \n",
    "                # Apply Laplace smoothing and calculate the likelihoods\n",
    "                self.likelihoods[cls][feature] = {\n",
    "                    value: (feature_counts.get(value, 0) + 1) / (total_cls_samples + total_feature_values)\n",
    "                    for value in X[feature].unique()\n",
    "                }\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Iterate over each test instance\n",
    "        for _, x in X_test.iterrows():\n",
    "            class_probabilities = {}  # Store the posterior probabilities for each class\n",
    "            \n",
    "            # Calculate the posterior probability for each class\n",
    "            for cls in self.classes:\n",
    "                # Initialize with the prior probability of the class\n",
    "                prob = self.class_priors[cls]\n",
    "                \n",
    "                # Multiply by the likelihoods (conditional probabilities) of each feature\n",
    "                for feature in self.features:\n",
    "                    value = x[feature]\n",
    "                    prob *= self.likelihoods[cls][feature].get(value, 1 / (len(self.likelihoods[cls][feature]) + len(self.features)))\n",
    "                \n",
    "                # Store the calculated probability for the class\n",
    "                class_probabilities[cls] = prob\n",
    "            \n",
    "            # Select the class with the highest posterior probability\n",
    "            predicted_class = max(class_probabilities, key=class_probabilities.get)\n",
    "            results.append(predicted_class)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca185a-0f28-4c5d-8f04-b71f4b111e4b",
   "metadata": {},
   "source": [
    "### Ejemplo de implementación\n",
    "\n",
    "El conjunto de datos 'Play Tennis' será importado para construir un clasificador Naive Bayes que prediga si se jugará al tenis o no, en función de las condiciones climáticas como la temperatura, la humedad y el viento. Las 14 instancias disponibles servirán como base de entrenamiento para el modelo, mientras que una nueva instancia, no incluida en el entrenamiento, se usará para evaluar su rendimiento y capacidad de generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff40be0a-14c5-47e9-8587-12d042553acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the instance {'outlook': 'sunny', 'temperature': 'cool', 'humidity': 'high', 'windy': True}: no\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('weather.nominal.csv')\n",
    "\n",
    "# Define X (features) and y (label)\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]  # Last column (label)\n",
    "\n",
    "# Train the classifier using the Naive Bayes algorithm with the original column names\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(X, y)\n",
    "\n",
    "# Create the instance to test: sunny, hot, normal, TRUE\n",
    "test_instance = pd.DataFrame([{\n",
    "    'outlook': 'sunny',\n",
    "    'temperature': 'cool',\n",
    "    'humidity': 'high',\n",
    "    'windy': True\n",
    "}])\n",
    "\n",
    "# Make the prediction\n",
    "prediction = nb_classifier.predict(test_instance)\n",
    "print(f\"Prediction for the instance {test_instance.iloc[0].to_dict()}: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58039da9-8b28-4157-b8d0-5363c6dce4ff",
   "metadata": {},
   "source": [
    "\n",
    "# Scikit-learn implementation\n",
    "\n",
    "The Naive Bayes algorithm is a simple and efficient probabilistic classifier that assumes conditional independence between features. While this assumption may not always hold in real-world data, Naive Bayes often performs remarkably well in many applications.\n",
    "\n",
    "Naive Bayes Classifier\n",
    "\n",
    "The Naive Bayes algorithm is built on Bayes' Theorem, which is expressed as:\n",
    "\n",
    "[ P(C|X) = \\frac{P(X|C)P(C)}{P(X)} ]\n",
    "\n",
    "where:\n",
    "\n",
    "    (P(C|X)) represents the posterior probability of class (C) given the data (X),\n",
    "    (P(X|C)) is the likelihood of the data given class (C),\n",
    "    (P(C)) is the prior probability of class (C),\n",
    "    (P(X)) is the probability of the data (which is constant for all classes and can be ignored for classification purposes).\n",
    "\n",
    "Gaussian Naive Bayes\n",
    "\n",
    "In the case of Gaussian Naive Bayes (GaussianNB), the algorithm assumes that the features follow a Gaussian (normal) distribution. The likelihood of a feature (x_i) given a class (C_k) is calculated using the probability density function of the Gaussian distribution:\n",
    "\n",
    "[ P(x_i | C_k) = \\frac{1}{\\sqrt{2\\pi \\sigma_k^2}} \\exp\\left(-\\frac{(x_i - \\mu_k)^2}{2\\sigma_k^2}\\right) ]\n",
    "\n",
    "where:\n",
    "\n",
    "    ( \\mu_k ) denotes the mean of feature (x_i) for class (C_k),\n",
    "    ( \\sigma_k^2 ) is the variance of feature (x_i) for class (C_k),\n",
    "    ( x_i ) represents the value of the feature for the given instance.\n",
    "\n",
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cb12c4-2f0f-487c-a2f5-a3ea29ad1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef7eb0d-d5ae-419b-bf29-ff8dab4692e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'weather.numeric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238cb255-77f2-437c-8863-c24aaf99753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Day   Outlook  Temperature  Humidity    Wind   Play\n",
      "0     1     sunny           85        85    weak  False\n",
      "1     2     sunny           80        90  strong  False\n",
      "2     3  overcast           83        86    weak   True\n",
      "3     4      rain           70        96    weak   True\n",
      "4     5      rain           68        80    weak   True\n",
      "5     6      rain           65        70  strong  False\n",
      "6     7  overcast           64        65  strong   True\n",
      "7     8     sunny           72        95    weak  False\n",
      "8     9     sunny           69        70    weak   True\n",
      "9    10      rain           75        80    weak   True\n",
      "10   11     sunny           75        70  strong   True\n",
      "11   12  overcast           72        90  strong   True\n",
      "12   13  overcast           81        75    weak   True\n",
      "13   14      rain           71        91  strong  False\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35c095a-f664-4bd0-b845-76419935d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook  Temperature  Humidity    Wind\n",
      "0     sunny           85        85    weak\n",
      "1     sunny           80        90  strong\n",
      "2  overcast           83        86    weak\n",
      "3      rain           70        96    weak\n",
      "4      rain           68        80    weak\n",
      "    Play\n",
      "0  False\n",
      "1  False\n",
      "2   True\n",
      "3   True\n",
      "4   True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# defining the dependent and independent variables\n",
    "X_train = df[['Outlook', 'Temperature', 'Humidity', 'Wind']]\n",
    "y_train = df[['Play']]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce6edb-5c74-4043-afc5-24d3a6d8f422",
   "metadata": {},
   "source": [
    "# De categorico a numerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513111b5-2c0f-47a7-8ea2-18f0936eb43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain']\n",
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n",
      "['weak', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'strong']\n",
      "[1 0 1 1 1 0 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "outlook = X_train.iloc[:,0]\n",
    "outlook_enc = encoder.fit_transform(outlook)\n",
    "print(outlook.tolist())\n",
    "print(outlook_enc)\n",
    "\n",
    "wind = X_train.iloc[:,3]\n",
    "wind_enc = encoder.fit_transform(wind)\n",
    "print(wind.tolist())\n",
    "print(wind_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0e7e0c-42c7-4502-867c-57b6a80fd1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook  Temperature  Humidity  Wind\n",
      "0         2           85        85     2\n",
      "1         2           80        90     2\n",
      "2         0           83        86     0\n",
      "3         1           70        96     1\n",
      "4         1           68        80     1\n",
      "5         1           65        70     1\n",
      "6         0           64        65     0\n",
      "7         2           72        95     2\n",
      "8         2           69        70     2\n",
      "9         1           75        80     1\n",
      "10        2           75        70     2\n",
      "11        0           72        90     0\n",
      "12        0           81        75     0\n",
      "13        1           71        91     1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_outlook = pd.DataFrame(outlook_enc, columns = ['Outlook'])\n",
    "df_wind = pd.DataFrame(outlook_enc, columns = ['Wind'])\n",
    "X_train_num = pd.concat([df_outlook, X_train.iloc[:,1], X_train.iloc[:,2], df_wind], axis=1)\n",
    "print(X_train_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21d3d2-6700-4961-9168-7361c3a1de27",
   "metadata": {},
   "source": [
    "# Generación del modelo\n",
    "\n",
    "Gaussian Naive Bayes. GaussianNB implements the Gaussian Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4f4332-ba0f-471f-820a-f3d886fb5b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andylmao/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB().fit(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3f5923-817f-4639-9fbe-3075c1912d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Outlook  Temperature  Humidity  Wind\n",
      "0        2           60        65     1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# sunny:2, hot:85, normal:65, strong:0 \n",
    "new_example = [[2, 60, 65, 1]]\n",
    "X_test = pd.DataFrame(new_example, columns = ['Outlook', 'Temperature', 'Humidity', 'Wind'])\n",
    "print(X_test)\n",
    "clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c072d1-b39e-440c-9a4d-68d6bd6416a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
