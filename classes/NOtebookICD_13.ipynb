{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e2b667-6da7-44a2-b1c9-acf6430f1987",
   "metadata": {},
   "source": [
    "# Notebook ICD - 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0010e44-fc59-4b72-944d-5a45fca6b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616d27a-3eac-470f-b09c-dd12c54d07d5",
   "metadata": {},
   "source": [
    "## ID3 desde cero\n",
    "\n",
    "ID3 (Iterative Dichotomiser 3) fue desarrollado en 1986 por Ross Quinlan. El algoritmo crea un árbol de decisiones de múltiples vías, encontrando para cada nodo (es decir, de manera voraz) la característica categórica que producirá la mayor ganancia de información para objetivos categóricos. Los árboles se expanden hasta su tamaño máximo y luego se aplica un paso de poda para mejorar la capacidad del árbol de generalizar a datos no vistos.\n",
    "\n",
    "C4.5 es el sucesor de ID3 y eliminó la restricción de que las características debían ser categóricas al definir dinámicamente un atributo discreto (basado en variables numéricas) que particiona el valor continuo del atributo en un conjunto discreto de intervalos. C4.5 convierte los árboles entrenados (es decir, el resultado del algoritmo ID3) en conjuntos de reglas if-then (si-entonces). Luego se evalúa la precisión de cada regla para determinar el orden en que deben aplicarse. La poda se realiza eliminando la condición previa de una regla si la precisión de la regla mejora sin ella.\n",
    "\n",
    "C5.0 es la última versión de Quinlan, lanzada bajo una licencia propietaria. Utiliza menos memoria y construye conjuntos de reglas más pequeños que C4.5, a la vez que es más preciso.\n",
    "\n",
    "## Estimación de Entropía\n",
    "\n",
    "La entropía mide la incertidumbre de un conjunto de datos. En esta función, se cuenta la frecuencia de cada clase y luego se utiliza la fórmula de entropía para calcular la cantidad de incertidumbre en las etiquetas de clase. La entropía alcanza su valor mínimo (cero) cuando todas las instancias pertenecen a una sola clase. Por el contrario, la entropía máxima (uno) se obtiene cuando hay una distribución perfectamente equilibrada entre las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984991be-7b67-4eb4-b8cb-646be57e2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    # Cuenta la frecuencia de una variable\n",
    "    counter = Counter(y)\n",
    "    total = len(y)\n",
    "    \n",
    "    # Calcula la entropía\n",
    "    ent = 0.0\n",
    "    for count in counter.values():\n",
    "        probability = count / total\n",
    "        ent -= probability * math.log2(probability)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b1f93-9ff4-4116-b6bf-2ee095b8c18c",
   "metadata": {},
   "source": [
    "# Calcular la ganancia de información\n",
    "\n",
    "La ganancia de información se basa en la disminución de la entropía al dividir los datos según un atributo. \n",
    "La función primero calcula la entropía total del conjunto de etiquetas y luego resta la entropía ponderada de cada subconjunto, lo que nos da la ganancia de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c5a5aa-4d5b-4a9f-91d3-88c6d5b6241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(X_column, y):\n",
    "    # Entropía del conjunto original\n",
    "    ent_total = entropy(y)\n",
    "    \n",
    "    # Dividir los datos por el valor de la característica\n",
    "    values, counts = np.unique(X_column, return_counts=True)\n",
    "    \n",
    "    # Entropía ponderada de los subconjuntos\n",
    "    weighted_entropy = 0.0\n",
    "    for value, count in zip(values, counts):\n",
    "        subset_y = y[X_column == value]\n",
    "        if len(subset_y) == 0:  # Verificamos si el subconjunto está vacío\n",
    "            continue\n",
    "        weighted_entropy += (count / len(y)) * entropy(subset_y)\n",
    "    \n",
    "    # Ganancia de información\n",
    "    return ent_total - weighted_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade3a74-4d19-420b-bcdd-7bdb8088fe49",
   "metadata": {},
   "source": [
    "# Seleccionar el mejor atributo\n",
    "\n",
    "Aquí iteramos sobre cada columna (atributo) en el conjunto de datos para calcular la ganancia de información. El atributo con la mayor ganancia de información se selecciona para realizar la partición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72106702-7eaf-4416-8983-5fea491db0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_attribute(X, y):\n",
    "    best_gain = -1\n",
    "    best_attr = None\n",
    "    \n",
    "    for col in X.columns:\n",
    "        gain = information_gain(X[col], y)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attr = col\n",
    "    return best_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed78bd-f72d-4fa5-b9bc-2eeacf48ad40",
   "metadata": {},
   "source": [
    "# Construir el árbol de decisión\n",
    "\n",
    "Esta es la implementación central del algoritmo ID3. Si todas las etiquetas son iguales, se crea un nodo hoja con la clase correspondiente. Si no quedan atributos, se asigna la clase mayoritaria. Se selecciona el mejor atributo con la mayor ganancia de información y se crea el nodo raíz. Luego, el conjunto de datos se divide y se construyen subárboles de manera recursiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1f73e3-4218-434a-9378-f35f69a193a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, children=None, *, label=None):\n",
    "        self.feature = feature  # El nombre del atributo\n",
    "        self.value = value  # El valor del atributo\n",
    "        self.children = children if children is not None else {}  # Subárboles\n",
    "        self.label = label  # Clase terminal\n",
    "\n",
    "def id3(X, y):\n",
    "    if len(np.unique(y)) == 1:  # Si todas las etiquetas son iguales\n",
    "        return Node(label=np.unique(y)[0])\n",
    "    \n",
    "    if X.empty:  # Si no hay más atributos\n",
    "        return Node(label=Counter(y).most_common(1)[0][0])  # Retornar la clase mayoritaria\n",
    "    \n",
    "    # Seleccionamos el mejor atributo\n",
    "    best_attr = best_attribute(X, y)\n",
    "    \n",
    "    # Creamos el nodo\n",
    "    root = Node(feature=best_attr)\n",
    "    \n",
    "    # Para cada valor posible del mejor atributo, creamos un subárbol\n",
    "    values = np.unique(X[best_attr])\n",
    "    for value in values:\n",
    "        subset_X = X[X[best_attr] == value].drop(columns=[best_attr])\n",
    "        subset_y = y[X[best_attr] == value]\n",
    "        \n",
    "        if len(subset_X) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Llamada recursiva a id3\n",
    "        subtree = id3(subset_X, subset_y)\n",
    "        root.children[value] = subtree\n",
    "    \n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45a606-3262-44b9-b5dc-8df859bc49c5",
   "metadata": {},
   "source": [
    "# Predicción (inferencia) con el árbol aprendido\n",
    "\n",
    "Para hacer predicciones, el árbol de decisión se recorre de manera recursiva. Al llegar a un nodo hoja, se devuelve la etiqueta asociada. En cada nodo interno, la decisión se toma en función del valor del atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c338556f-6b27-4867-8a8b-1475d4065696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, X_test):\n",
    "    if tree.label is not None:  # Nodo hoja\n",
    "        return tree.label\n",
    "    \n",
    "    value = X_test[tree.feature]  \n",
    "    if value in tree.children:\n",
    "        return predict(tree.children[value], X_test)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb03db-2aa1-4afc-890a-5def247be01e",
   "metadata": {},
   "source": [
    "# Ejemplo de implementación\n",
    "\n",
    "El algoritmo ID3 se aplicará al conjunto de datos 'Play Tennis' para construir un árbol de decisión que prediga si jugar al tenis o no, basado en condiciones meteorológicas como la temperatura, la humedad y el viento. Las 14 instancias disponibles servirán como base de entrenamiento para el modelo, mientras que una nueva instancia, no incluida en el entrenamiento, se usará para evaluar su rendimiento y capacidad de generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a033557e-0bcf-4938-ba02-458dcfc157f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción para la instancia {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'normal', 'windy': True}: yes\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('weather.nominal.csv')\n",
    "\n",
    "# Definir X (características) e y (etiqueta)\n",
    "X = data.iloc[:, :-1]  # Todas las columnas menos la última\n",
    "y = data.iloc[:, -1]  # Última columna (etiqueta)\n",
    "\n",
    "# Entrenar el árbol de decisión usando el algoritmo ID3 con los nombres originales de las columnas\n",
    "tree = id3(X, y)\n",
    "\n",
    "# Crear la instancia para probar: sunny, hot, normal, TRUE\n",
    "test_instance = {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'normal', 'windy': True}\n",
    "\n",
    "# Realizar la predicción\n",
    "prediction = predict(tree, test_instance)\n",
    "print(f'Predicción para la instancia {test_instance}: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5818681-0109-467f-b1c5-383d962c9819",
   "metadata": {},
   "source": [
    "\n",
    "# Scikit-learn implementation\n",
    "\n",
    "CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node. Scikit-learn uses an optimized version of the CART algorithm.\n",
    "\n",
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36266bc3-d306-499e-b748-f5567aee6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b670463-26c7-45a8-9e18-784a6a0c722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'weather.nominal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048194d1-a4f1-4a97-b6af-a540144017c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outlook temperature humidity  windy play\n",
      "0      sunny         hot     high  False   no\n",
      "1      sunny         hot     high   True   no\n",
      "2   overcast         hot     high  False  yes\n",
      "3      rainy        mild     high  False  yes\n",
      "4      rainy        cool   normal  False  yes\n",
      "5      rainy        cool   normal   True   no\n",
      "6   overcast        cool   normal   True  yes\n",
      "7      sunny        mild     high  False   no\n",
      "8      sunny        cool   normal  False  yes\n",
      "9      rainy        mild   normal  False  yes\n",
      "10     sunny        mild   normal   True  yes\n",
      "11  overcast        mild     high   True  yes\n",
      "12  overcast         hot   normal  False  yes\n",
      "13     rainy        mild     high   True   no\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c70c84d4-5b05-48dc-b156-24fa355c38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outlook temperature humidity  windy\n",
      "0     sunny         hot     high  False\n",
      "1     sunny         hot     high   True\n",
      "2  overcast         hot     high  False\n",
      "3     rainy        mild     high  False\n",
      "4     rainy        cool   normal  False\n",
      "  play\n",
      "0   no\n",
      "1   no\n",
      "2  yes\n",
      "3  yes\n",
      "4  yes\n"
     ]
    }
   ],
   "source": [
    "# defining the dependent and independent variables\n",
    "X_train = df[['outlook', 'temperature', 'humidity', 'windy']]\n",
    "y_train = df[['play']]\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc45f33-d3ea-4fc7-bd1d-09f1a331dff9",
   "metadata": {},
   "source": [
    "# De categórico a numérico\n",
    "\n",
    "Scikit-learn utiliza una versión optimizada del algoritmo CART; sin embargo, la implementación de scikit-learn no admite variables categóricas por el momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acd04a2a-0443-4257-bd61-715047ada53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy', 'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast', 'overcast', 'rainy']\n",
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n",
      "['hot', 'hot', 'hot', 'mild', 'cool', 'cool', 'cool', 'mild', 'cool', 'mild', 'mild', 'mild', 'hot', 'mild']\n",
      "[1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "['high', 'high', 'high', 'high', 'normal', 'normal', 'normal', 'high', 'normal', 'normal', 'normal', 'high', 'normal', 'high']\n",
      "[0 0 0 0 1 1 1 0 1 1 1 0 1 0]\n",
      "[False, True, False, False, False, True, True, False, False, False, True, True, False, True]\n",
      "[0 1 0 0 0 1 1 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "outlook = X_train.iloc[:,0]\n",
    "outlook_enc = encoder.fit_transform(outlook)\n",
    "print(outlook.tolist())\n",
    "print(outlook_enc)\n",
    "\n",
    "temperature = X_train.iloc[:,1]\n",
    "temperature_enc = encoder.fit_transform(temperature)\n",
    "print(temperature.tolist())\n",
    "print(temperature_enc)\n",
    "\n",
    "humidity = X_train.iloc[:,2]\n",
    "humidity_enc = encoder.fit_transform(humidity)\n",
    "print(humidity.tolist())\n",
    "print(humidity_enc)\n",
    "\n",
    "wind = X_train.iloc[:,3]\n",
    "wind_enc = encoder.fit_transform(wind)\n",
    "print(wind.tolist())\n",
    "print(wind_enc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc5647ed-5885-4bb9-a473-63bfd1fd0125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook temperature  windy  Wind\n",
      "0         2         hot  False     2\n",
      "1         2         hot   True     2\n",
      "2         0         hot  False     0\n",
      "3         1        mild  False     1\n",
      "4         1        cool  False     1\n",
      "5         1        cool   True     1\n",
      "6         0        cool   True     0\n",
      "7         2        mild  False     2\n",
      "8         2        cool  False     2\n",
      "9         1        mild  False     1\n",
      "10        2        mild   True     2\n",
      "11        0        mild   True     0\n",
      "12        0         hot  False     0\n",
      "13        1        mild   True     1\n"
     ]
    }
   ],
   "source": [
    "df_outlook = pd.DataFrame(outlook_enc, columns = ['Outlook'])\n",
    "\n",
    "#df_temperature = pd.DataFrame(outlook_enc, columns = ['temperature'])\n",
    "# df_humidity = pd.DataFrame(outlook_enc, columns = ['humidity'])\n",
    "df_wind = pd.DataFrame(outlook_enc, columns = ['Wind'])\n",
    "X_train_num = pd.concat([df_outlook, X_train.iloc[:,1], X_train.iloc[:,3], df_wind], axis=1)\n",
    "print(X_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4e4dc-1a6a-414f-80f4-2648dfe7e8b7",
   "metadata": {},
   "source": [
    "# Build the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28a0b56-96a8-425a-901a-8716d6836712",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'hot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:252\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    249\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:645\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[1;32m    644\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[0;32m--> 645\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[1;32m    647\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    920\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 921\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    923\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'hot'"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier().fit(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decb464d-94c6-4c9c-bc46-c12612dccc9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m X_train_num\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 3\u001b[0m text_representation \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mexport_text(\u001b[43mclf\u001b[49m, feature_names \u001b[38;5;241m=\u001b[39m features)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_representation)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "features = X_train_num.columns.values.tolist()\n",
    "text_representation = tree.export_text(clf, feature_names = features)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d7aa5-f5e9-4b13-89c9-3fd9e14c2fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
