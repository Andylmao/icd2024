{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8787849-b029-481f-a1f1-95b5443809ca",
   "metadata": {},
   "source": [
    "# Notebook ICD - 16\r\n",
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ab53fc-db04-4aa5-a2bf-4889b29e2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997de3a-e443-4dcd-9d7c-8bef04d53ca4",
   "metadata": {},
   "source": [
    "# **SVM desde cero**  \r\n",
    "Esta implementación sigue los principios básicos de las Máquinas de Vectores de Soporte (SVM), donde el objetivo principal es encontrar el hiperpunto óptimo que separa las clases. El clasificador se inicializa con tres parámetros clave:\r\n",
    "\r\n",
    "- **Tasa de aprendizaje:** controla cuán rápido se ajusta el modelo durante el entrenamiento.  \r\n",
    "- **Parámetro de regularización (lambda):** previene el sobreajuste al equilibrar el margen y los errores.  \r\n",
    "- **Número de iteraciones:** establece cuántas veces el algoritmo debe iterar sobre el conjunto de datos para optimizar el hiperpunto.\r\n",
    "\r\n",
    "Dentro de la clase, el método `fit` se utiliza para entrenar el modelo ajustando los pesos (\\(w\\)) y el sesgo (\\(b\\)) a través del descenso de gradiente. Durante el entrenamiento, cada punto de datos se clasifica según si satisface la condición del margen, y si no lo hace, tanto los pesos como el sesgo se actualizan en consecuencia.\r\n",
    "\r\n",
    "El método `predict` utiliza los pesos y el sesgo aprendidos para clasificar nuevas instancias calculando el signo de la frontera de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681806f0-8c62-4735-8031-ebf1fe791be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
    "        \"\"\"\n",
    "        Initialize the SVM with hyperparameters for learning rate, regularization, and number of iterations.\n",
    "        \n",
    "        learning_rate: The step size for each iteration of gradient descent.\n",
    "        lambda_param: Regularization parameter to prevent overfitting.\n",
    "        n_iters: The number of times the algorithm will iterate over the dataset to find the optimal hyperplane.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate  # Controls the speed of convergence\n",
    "        self.lambda_param = lambda_param    # Regularization parameter (controls the margin)\n",
    "        self.n_iters = n_iters              # Number of training iterations\n",
    "        self.w = None                       # Weight vector (learned parameters)\n",
    "        self.b = None                       # Bias term\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the SVM model using the training data.\n",
    "        \n",
    "        X: The training feature matrix (n_samples, n_features)\n",
    "        y: The training labels (n_samples,). Labels should be in {-1, 1}.\n",
    "        \n",
    "        This method applies gradient descent to optimize the weights (w) and bias (b)\n",
    "        to maximize the margin between the classes.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        y_ = np.where(y <= 0, -1, 1)  # Convert labels to -1 and 1 for SVM\n",
    "\n",
    "        # Initialize the weight vector and bias term\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        # Gradient descent optimization loop\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    # If the condition holds, apply a regularization update (no penalty)\n",
    "                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    # If the condition fails, apply the update to w and b to penalize the misclassification\n",
    "                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
    "                    self.b -= self.learning_rate * y_[idx]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for the test data.\n",
    "        \n",
    "        X: Test feature matrix.\n",
    "        \n",
    "        Returns the predicted labels (either -1 or 1).\n",
    "        \"\"\"\n",
    "        # Return the sign of the dot product (linear decision boundary)\n",
    "        return np.sign(np.dot(X, self.w) - self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d58a45-c5ae-4f11-acfc-7811349feb36",
   "metadata": {},
   "source": [
    "# **Ejemplo de implementación**  \r\n",
    "Siguiendo la definición de SVM, el conjunto de datos de Clima (Jugar al tenis) se carga en memoria utilizando pandas. Este conjunto de datos incluye varios atributos relacionados con el clima, como perspectiva, temperatura, humedad y viento, que se utilizan para predecir si se puede jugar al tenis. Esta etapa prepara los datos en bruto para un posterior preprocesamiento.\r\n",
    "\r\n",
    "El siguiente paso, el preprocesamiento de datos, es esencial porque SVM requiere entrada numérica. Cada característica categórica en el conjunto de datos (por ejemplo, soleado, caluroso, normal) se asigna a un valor entero correspondiente, lo que permite que el algoritmo procese la información de manera efectiva. La etiqueta objetivo (si se puede jugar al tenis o no) también se convierte en valores numéricos (0 para \"no\" y 1 para \"sí\").\r\n",
    "\r\n",
    "Una vez que se completa el preprocesamiento, el conjunto de datos se divide en características y etiquetas. La matriz de características (\\(X\\)) incluye todas las condiciones climáticas (perspectiva, temperatura, humedad, viento), mientras que el vector de etiquetas (\\(y\\)) contiene los valores objetivo (jugar al tenis: sí o no). Esta separación permite que el modelo aprenda del conjunto de características mientras predice las etiquetas objetivo correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca92010-5724-42a8-8e84-55222fdfc7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outlook temperature humidity  windy play\n",
      "0     sunny         hot     high  False   no\n",
      "1     sunny         hot     high   True   no\n",
      "2  overcast         hot     high  False  yes\n",
      "3     rainy        mild     high  False  yes\n",
      "4     rainy        cool   normal  False  yes\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (assumed to be uploaded or present in the local system)\n",
    "data = pd.read_csv('weather.nominal.csv')\n",
    "print(data.head())\n",
    "\n",
    "# Convert categorical variables into numerical values for KNN\n",
    "data['outlook'] = data['outlook'].map({'sunny': 0, 'overcast': 1, 'rainy': 2})\n",
    "data['temperature'] = data['temperature'].map({'hot': 0, 'mild': 1, 'cool': 2})\n",
    "data['humidity'] = data['humidity'].map({'high': 0, 'normal': 1})\n",
    "data['windy'] = data['windy'].astype(int)\n",
    "data['play'] = data['play'].map({'no': -1, 'yes': 1})\n",
    "\n",
    "# Define X (features) and y (labels)\n",
    "X = data.drop(columns='play').values  # Features\n",
    "y = data['play'].values  # Labels\n",
    "\n",
    "# Show the first transformed data\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad32c4-a829-4bb1-946d-502ad8faa625",
   "metadata": {},
   "source": [
    "A continuación, el clasificador SVM se inicializa con los hiperparámetros especificados, y se ejecuta el proceso de entrenamiento utilizando el método `fit`. El modelo itera sobre el conjunto de datos múltiples veces, ajustando el hiperpunto para maximizar el margen entre las dos clases (sí y no). A través de cada iteración, mejora su capacidad de predicción refinando el vector de pesos y el sesgo para minimizar los errores de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f02c1d-fb42-4665-b178-97a5fb470c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Train the SVM Classifier\n",
    "svm = SVM(learning_rate=0.001, lambda_param=0.01, n_iters=1000)\n",
    "svm.fit(X, y)\n",
    "\n",
    "# This step initializes the SVM classifier with a specified learning rate, regularization parameter (lambda), and the number of iterations.\n",
    "# The `fit` method is used to train the classifier using the feature matrix X and the target labels y.\n",
    "# The model optimizes the weights and bias to create a hyperplane that separates the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554980d1-897e-48d0-83bb-b35f1283fc1f",
   "metadata": {},
   "source": [
    "Una vez que el modelo está entrenado, se crea una instancia de prueba para simular nuevas condiciones climáticas (soleado, caluroso, humedad normal y ventoso). Esta instancia se representa como un arreglo numérico, donde cada característica está codificada para coincidir con el formato utilizado durante el entrenamiento. Finalmente, se emplea el método `predict` del clasificador para clasificar esta instancia de prueba. Basado en el hiperpunto aprendido, el modelo determina si es un día adecuado para jugar al tenis, y el resultado se muestra como \"sí\" o \"no\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7540fd6c-92c8-4365-9d7d-57a6aa498c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the test instance: yes\n"
     ]
    }
   ],
   "source": [
    "# Create a Test Instance\n",
    "test_instance = np.array([[0, 0, 1, 1]])  # sunny, hot, normal, TRUE\n",
    "\n",
    "# This step defines a new test instance that represents a weather condition: sunny, hot, normal humidity, and windy.\n",
    "# The instance is passed as a NumPy array, where each feature is encoded numerically (sunny = 0, hot = 0, normal = 1, windy = TRUE = 1).\n",
    "\n",
    "# Make a Prediction\n",
    "prediction = svm.predict(test_instance)\n",
    "print(f\"Prediction for the test instance: {'yes' if prediction[0] == 1 else 'no'}\")\n",
    "\n",
    "# Finally, the trained SVM classifier makes a prediction on the test instance.\n",
    "# The `predict` method returns a label: either 1 (yes, play tennis) or -1 (no, don't play tennis).\n",
    "# The output is printed, interpreting the predicted label in the context of the weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0001a32-0abb-4237-bc4b-4282bd48ba99",
   "metadata": {},
   "source": [
    "**Implementación en Scikit-learn**  \r\n",
    "Las máquinas de vectores de soporte (SVM) son un conjunto de métodos de aprendizaje supervisado utilizados para clasificación, regresión y detección de outliers. Las ventajas de las máquinas de vectores de soporte incluyen:\r\n",
    "\r\n",
    "- Efectivas en espacios de alta dimensionalidad.\r\n",
    "- Siguen siendo efectivas en casos donde el número de dimensiones es mayor que el número de muestras.\r\n",
    "- Utilizan un subconjunto de puntos de entrenamiento en la función de decisión (llamados vectores de soporte), por lo que también son eficientes en memoria.\r\n",
    "- Versátiles: se pueden especificar diferentes funciones de núcleo para la función de decisión. Se proporcionan núcleos comunes, pero también es posible especificar núcleos personalizados.\r\n",
    "\r\n",
    "Las desventajas de las máquinas de vectores de soporte incluyen:\r\n",
    "\r\n",
    "- Si el número de características es mucho mayor que el número de muestras, evitar el sobreajuste al elegir funciones de núcleo y el término de regularización es crucial.\r\n",
    "- Las clases SVC, NuSVC y LinearSVC son capaces de realizar clasificación binaria y multiclase en un conjunto de datos. La implementación de C-Support Vector Classification (SVC) se basa en libsvm. El tiempo de ajuste escala al menos de forma cuadrática con el número de muestras y puede ser poco práctico más allá de decenas de miles de muestras. Para conjuntos de datos grandes, considera usar LinearSVC o SGDClassifier en su lugar, posiblemente después de un transformador de Nystroem u otra aproximación de núcleo.\r\n",
    "\r\n",
    "El soporte para múltiples clases se maneja según un esquema de uno contra uno."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
